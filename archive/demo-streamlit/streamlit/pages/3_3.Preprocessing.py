
import streamlit as st
from PIL import Image
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os
import requests

# This is relative root directory af trai and test images
#IMAGES_ROOT = os.path.join(os.getcwd(), "images")
IMAGES_ROOT = r"https://www.anigraphics.fr/images"



st.title("Analyse et preprocessing")


def isFileExist(fileFullPath):
    if fileFullPath is not None:
        if os.path.isfile(fileFullPath):
            if os.path.exists(fileFullPath):
                return True
            else:
                return False
        else:
            return False
    else:
        return False


def get_codes_df():
    cats = {
            '10' : 'Livres anciens / occasion',
            '40' : 'Jeux vid√©os anciens, √©quipement',
            '50' : 'Accessoires & produits d√©riv√©s gaming',
            '60' : 'Consoles de jeu',
            '1140' : 'Figurines',
            '1160' : 'Cartes de jeu',
            '1180' : 'Figurines & Jeux de Soci√©t√©',
            '1280' : 'Jeux & jouets pour enfants',
            '1281' : 'Jeux de soci√©t√©',
            '1300' : 'Mod√©lisme',
            '1301' : 'V√™tements b√©b√© et jeux pour la maison',
            '1302' : 'Jeux & jouets d\'ext√©rieur pour enfants',
            '1320' : 'Jouets & accessoires pour b√©b√©',
            '1560' : 'Meubles d\'int√©rieur',
            '1920' : 'Linge de maison',
            '1940' : 'Alimentation & vaisselle',
            '2060' : 'Objets d√©coration maison',
            '2220' : 'Equipement pour animaux',
            '2280' : 'Journaux, revues, magazines anciens',
            '2403' : 'Livres, BD, magazines anciens',
            '2462' : 'Consoles, jeux et √©quipement occasion',
            '2522' : 'Papeterie',
            '2582' : 'Meubles d\'ext√©rieur',
            '2583' : 'Equipement pour piscine',
            '2585' : 'Outillage int√©rieur / ext√©rieur, t√¢ches m√©nag√®res',
            '2705' : 'Livres neufs',
            '2905' : 'Jeux PC',
        }
    df_codes = pd.DataFrame({'prdtypecode': list(cats.keys()), 'cat√©gorie': list(cats.values())})
    return df_codes
    

pickles_apth = "../../pickles/cleaned_data.pkl"
print("Reading from pickle file from " + f"{pickles_apth} ...")
df = pd.read_pickle(f"{pickles_apth}")

df_codes = get_codes_df()
df_codes['prdtypecode'] = df_codes['prdtypecode'].astype(int)
df['prdtypecode'] = df['prdtypecode'].astype(int)
df_with_cats = pd.merge(left=df, left_on='prdtypecode', right=df_codes, right_on='prdtypecode' ).sort_values(by='cat√©gorie')

df_with_cats['prdtypecode'] = df_with_cats['prdtypecode'].astype('Int64')
df_with_cats.index = df_with_cats.index.astype('int64') 


#import io
#buffer = io.StringIO()
#df_with_cats.info(buf=buffer)
#s = buffer.getvalue()
#st.text(s)
#st.dataframe(df_with_cats)


# Configuration des tabs
tabs_title = ["üöÄTexte & Image", "üöÄTexte uniquement", "üöÄImages uniquement"]
tab0, tab1, tab2 = st.tabs(tabs_title)

# TAB Analyse du texte
with tab0:
    st.header("‚≠êExploration du texte et images")
    st.write("L'objectif de l‚Äôexercice d‚Äôexploration est de :") 
    st.write("1- Identifier dans quelle mesure le contenu de la ¬´ d√©signation ¬ª et de la ¬´ description ¬ª peut se rapporter √† un type de produit")
    st.write("2- Quel type de nettoyage des donn√©es doit √™tre effectu√© pour que les donn√©es textuelles soient les plus pertinentes ?")
    st.write("3- D√©terminer la s√©mantique derri√®re le code de type de produit en affichant des images al√©atoires et les principaux mots-cl√©s pour chaque code de type de produit, ce qui aiderait √† une meilleure interpr√©tation humaine des r√©sultats au cours de l'exp√©rimentation du mod√®le.")
    img_explore_txt_byprdcode = Image.open(os.path.join(os.getcwd(), "images", "explore-txt-prdcat.png"))
    st.image(img_explore_txt_byprdcode)

    st.header("‚≠êConclusions")
    st.divider()
    st.write("La combinaison de la ¬´ d√©signation ¬ª et de la ¬´ description ¬ª semble donner de meilleurs r√©sultats en termes d'identification des caract√©ristiques li√©es au type de produit.")
    st.divider()
    st.write("Les termes (token) pouvant √™tre ignor√©s :")
    st.write("* Stop words pour l‚Äôanglais et le fran√ßais")
    st.write("* ponctuation")
    st.write("* vocabulaire des dimensions : cm, mm, hauteur, etc.")
    st.write("* vocabulaire des couleurs : blanc, gris, etc.")
    st.write("* Balises et encodage HTML")
    st.write("* Valeurs num√©riques")
    st.write("* Besoin de lemmatisation : processus de r√©duction d'un token √† son lemme")
    st.divider()
    st.write("La liste des cat√©gories descriptives a √©t√© √©tablie comme suit :")
    st.dataframe(df_codes)


with tab1:
    
    img_analyse_graphe_1 = Image.open(os.path.join(os.getcwd(), "images",  "analyse_graphe_1.png"))
    img_analyse_graphe_2 = Image.open(os.path.join(os.getcwd(), "images",  "analyse_graphe_2.png"))
    img_analyse_graphe_3 = Image.open(os.path.join(os.getcwd(), "images",  "analyse_graphe_3.png"))
    img_analyse_graphe_4 = Image.open(os.path.join(os.getcwd(), "images",  "analyse_graphe_4.png"))
    
    #img_analyse_graphe_1 = Image.open(requests.get(IMAGES_ROOT +  "/"  + "analyse_graphe_1.png", stream=True).raw)
    #img_analyse_graphe_2 = Image.open(requests.get(IMAGES_ROOT +  "/"  + "analyse_graphe_2.png", stream=True).raw)
    #img_analyse_graphe_3 = Image.open(requests.get(IMAGES_ROOT +  "/"  + "analyse_graphe_3.png", stream=True).raw)
    #img_analyse_graphe_4 = Image.open(requests.get(IMAGES_ROOT +  "/"  + "analyse_graphe_4.png", stream=True).raw)
    
    
    st.header("Graphes de r√©partitions avant le cleanning")
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.html("<h4>‚≠ê<span  style='color:orange'>R√©partition des cat√©gories selon les decriptions associ√©es :</span></h4>")
        st.image(img_analyse_graphe_1)
        st.write("1.	Pour certaines cat√©gories (parties noires) les valeurs nulles sont majoritaires, ce qui les p√©nalise comparativement aux autres cat√©gories. \
                Cela peut √©ventuellement avoir une cons√©quence dans la pr√©diction de ces cat√©gories au profit des autres.")
        st.write("2.	M√™me en ignorant les valeurs nulles, un d√©s√©quilibre subsiste toutefois, comme on le remarque clairement dans le graphe en bas.") 
        st.write("3.	Les cat√©gories qui repr√©sentent clairement des cas anormaux, voire aberrants comparativement au reste, \
            comme le **2583**, ce qui risque de le favoriser dans les pr√©dictions par l‚Äôeffet de l‚Äô**OVERFITTING**") 
        st.write("4.	Ce constat est le m√™me concernant le code cat√©gorie 2583 en ce qui concerne aussi la variable ‚Äòdesignation‚Äô")
        st.write("5.	Trois cat√©gories qui sortent du lot, **1920, 2522 et 2583** repr√©sentent un nombre important de lignes non nulles et dupliqu√©es")

        

    with col2:
        
        st.html("<h4>‚≠ê<span  style='color:orange'>R√©partition des cat√©gories selon les designations associ√©es :</span></h4>")
        st.image(img_analyse_graphe_2)
        st.write("On note bien que malgr√© ces trois distinctions, le d√©s√©quilibre subsiste ! Il s'accentue m√™me pour quelques cat√©gories en bas de l‚Äô√©chelle, \
            comme **60, 1180, 1301, 1940 et 2220**. Autrement dit, ces cat√©gories seront moins fournies en termes de texte.")
    
    with col3:
        st.html("<h4>‚≠ê<span  style='color:orange'>R√©partition des cat√©gories selon les designations associ√©es apr√®s le cleaning :</span></h4>")
        st.image(img_analyse_graphe_3)
        st.html("Les actions suivantes ont √©t√© men√©es pour donner la nouvelle r√©partition des cat√©gories ci-dessous un peu mieux √©quilibr√©e que pr√©c√©demment\
            <ul><li>Suppression des valeurs nulles</li><ul>\
            <ul><li>Suppression des doublons</li><ul>\
            <ul><li>Suppression des expressions n'apportant aucune valeur s√©mantique relative au produit</li><ul>\
            <ul><li>Ajout d'une variable descriptive des 27 catgories √† partir de l'analyse des images associ√©es aux produits</li><ul>")
        
    
    st.html("<h4><span style='color:orange'>Cartographie en cloud des mots apr√®s le cleaning :</span></h4>") 
    st.html("<p>Les mots en fonction de leur taille dans le cloud, r√©v√®lent leurs fr√©quence dans les deux variables explicatives combin√©es,\
            la d√©signation des produits et la description associ√©e. D'une mani√®re indirecte, les mots mis plus en avant r√©v√®lent la cat√©gorie des produits\
            la plus dominante en terme de description comme les mot <span style='color: red'><strong>jeu, enfant, sac, piscine...</strong></span></p>")
    st.image(img_analyse_graphe_4)
    
        
    st.html("<hr")    
    
    
    st.header("Graphes de r√©partitions apr√®s le cleanning en live")
    #   Load some graphs in live
    def drawBtn_1():
        btn_load_graphs = st.button("Charger les graphes",  type="primary" )
        if btn_load_graphs:
            load_graphs()
            st.text("Les graphes ont √©t√© charg√©s !")
    
    def load_graphs():  
        if isFileExist(pickles_apth):
            col1, col2, col3 = st.columns(3)
            
            sns.set_theme(rc={'figure.figsize': (10, 7)})
            fig, ax = plt.subplots(nrows= 1, ncols= 1)
            
            with col1:
                st.write(">Distribution de la longueur de la variable **desi_desc**")
                g1 = sns.histplot(x=df['desi_desc'].str.split().map(lambda x: len(x)), ax=ax, kde=True, bins=range(0, 400))
                g1.set_xlim(0,400)
                g1.set_xlabel("Longueur du texte 'desi_desc'")
                g1.set_ylabel("Nombre de 'desi_desc'")
                g1.set_title("Distribution de la longueur de la variable 'desi_desc'")
                g1.set_gid(True)
                st.pyplot(g1.figure)
                st.write(">Un nombre important de lignes poss√®dent une longeurs importante du texte **desi_desc**. \
                    Le calcul des quartiles standards Q1, Q2 et Q3, r√©v√®leront l'ampleur des outiliers sur la base \
                    de l'indicateur de dispertion sup√©rieure : **Q3 + 1.5*IQR**. Voir graphe √† droite.")
            
            with col2:
                st.write(">Distribution en BOXPLOT (Moustache) de la longueur de la variable **desi_desc**")
                df['desc_length'] = df['desi_desc'].apply(lambda x: len(str(x)))
                g2 = sns.boxplot(data=df, y='desc_length', ax=ax, hue='prdtypecode', gap=1.5, palette='pastel')
                g2.set_ylabel("Longueur du texte")
                g2.set_title("Distribution de la longueur de la variable 'desi_desc'")
                st.pyplot(g2.figure)
                st.write(">La majorit√© des cat√©gories poss√©dent des outiliers sup√©rieurs a des ampleurs qui ne sont pas au m√™me niveau.\
                    Cela est la cons√©quence de leur nombre et de la longeur du texte aussi")
            
            with col3:
                st.write(">Distribution du nombre de produits par cat√©gorie")
                g3 =sns.countplot(data=df_with_cats,  x='prdtypecode',  orient='v', palette='Spectral')
                g3.set_title("Distribution en nombre de produits par cat√©gorie")
                g3.set_xlabel('Cat√©gories')
                g3.set_ylabel('Nombre de produits')
                ax.tick_params(axis='x', rotation=90)
                plt.legend(loc='lower left')
                #g3.set_xticklabels(labels=df_with_cats["cat√©gorie"].unique())
                st.pyplot(g3.figure)
                st.write(">On voit clairement un d√©s√©quilibre dans cette r√©partition qui peut √™tre une \
                    source d‚ÄôOVERFITING ou de r√©sultats de pr√©diction erron√©es en faveur des cat√©gories \
                        dominantes comme la **2583** qui pr√©sente un cas aberrant ! ")
            
            #st.bar_chart(df_with_cats, x="cat√©gorie", y="prdtypecode", color="cat√©gorie", x_label ="Cat√©gories", y_label="Nombre de produits", stack=False)
            
        else:
            st.html("Fichier PICKLE introuvable ici : " + pickles_apth)

    # action button
    drawBtn_1()


# TAB Analyse des images"
with tab2:
    img_explore_images_1 = Image.open(os.path.join(os.getcwd(), "images", "freq_img_taille_bits.png"))
    img_explore_images_2 = Image.open(os.path.join(os.getcwd(), "images", "boxplot_img_taille_bits.png"))
    img_explore_images_3 = Image.open(os.path.join(os.getcwd(), "images", "anova_test_img_taille_bits.jpg"))
    
    #img_explore_images_1 = Image.open(requests.get(IMAGES_ROOT +  "/"  + "freq_img_taille_bits.png", stream=True).raw)
    #img_explore_images_2 = Image.open(requests.get(IMAGES_ROOT +  "/"  + "boxplot_img_taille_bits.png", stream=True).raw)
    #img_explore_images_3 = Image.open(requests.get(IMAGES_ROOT +  "/"  + "anova_test_img_taille_bits.jpg", stream=True).raw)
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.header("‚≠êFr√©quences des tailles des images (en bits)")
        st.image(img_explore_images_1)
        st.write("Ce graphe exprime la fr√©quence des images en fonction de leur poids, une piste que \
            nous choisissons d'explorer. On observe une distribution gaussienne, la **plus grande partie des images \
            p√®se environ 20 000 bits, soit 20 kilobit**")


    with col2:
        st.header("‚≠êGraphe boxplot des tailles")
        st.image(img_explore_images_2)
        st.write("Ce graphe Exprime la distribution de la taille des images en fonction des cat√©gories \
                 m√©diane, √©carts interquartiles et outliers. **Nous remarquons que cette distribution est assez disparate, \
                nous avons donc de bonnes raisons de penser que la taille des images influe sur la cat√©gorie**")

    with col3:
        st.header("‚≠êTest ANOVA sur les tailles des images")
        st.image(img_explore_images_3)
        st.write("Nous r√©alisons un test ANOVA (qui sert √† savoir si plusieurs groupes ont des \
                diff√©rences significatives entre eux) avec les hypoth√®ses suivantes:")
        st.write("> H0 : La taille des images n'a pas d'influence sur la cat√©gorie")
        st.write("> H1 : La taille des images a une influence sur la cat√©gorie")
        st.write("Au vu des r√©sulats (**p-value tr√®s inf√©rieure √† 0.05**) et **F-stat tr√®s √©lev√©e (+ de 339)**, on peut rejeter \
                l'hypoth√®se H0 au profit de la H1 : la taille des images a une influence sur la cat√©gorie. \
                C'est donc une feature qui pourrait √©ventuellement nous servir par la suite pour cat√©goriser les images, \
                mais nous n'en aurons pas besoin au final car les features les plus √©videntes (valeurs de pixels des img) suffiront.")

    st.html("<hr")

  
    img_analyse_images_1 = Image.open(os.path.join(os.getcwd(), "images",  "exemple_preprocess_baseline.png"))
    img_analyse_images_2 = Image.open(os.path.join(os.getcwd(), "images",  "exemple_preprocess_deeplearning.png"))
    img_analyse_images_3 = Image.open(os.path.join(os.getcwd(), "images",  "exemple_preprocess_generique.png"))
    
    #img_analyse_images_1 = Image.open(requests.get(IMAGES_ROOT +  "/"  + "exemple_preprocess_baseline.png", stream=True).raw)
    #img_analyse_images_2 = Image.open(requests.get(IMAGES_ROOT +  "/"  + "exemple_preprocess_deeplearning.png", stream=True).raw)
    #img_analyse_images_3 = Image.open(requests.get(IMAGES_ROOT +  "/"  + "exemple_preprocess_generique.png", stream=True).raw)
    
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.header("‚≠êPreprocessing g√©n√©rique")
        st.image(img_analyse_images_1)
        st.write("Un exemple d'images preprocess√©es qui pourront nous servir pour tous les mod√®les (pas de r√©duction de taille, pas \
            d'alt√©ration de la qualit√©, 1000 images par cat√©gorie et transfos)")
        
    with col2:
        st.header("‚≠êPreprocess deep-learning")
        st.image(img_analyse_images_2)
        st.write("Un exemple d'images preprocess√©es pour les mod√®les deeplearning (la library utilis√©e est \
            **keras**, r√©duction taille en 224x224 et transfos")
   
    with col3:
        st.header("‚≠êPreprocessing baseline")
        st.image(img_analyse_images_3)
        st.write("Un exemple_preprocess_baseline : un exemple d'images preprocess√©es pour les mod√®les baseline \
            (taille r√©duite, niveaux de gris et transfos")
   

    
    st.html("<span  style='color:orange; font-size: 24px;'>Nous avons effectu√© 3 types de preprocessing :</span>")
    
    st.write("1. **Un preprocessing g√©n√©rique**: utilisable par tout type de mod√®les. Il contient 1000 images par cat√©gorie, et \
    30% des images ont √©t√© **augment√©es** (rotations, zoom, etc.) pour diversifier le dataset. Leur taille est inchang√©e  \
    (500x500) et pourra par la suite √™tre adapt√©e en fonction des mod√®les (voir **exemple_preprocess_generique**")
    
    st.write("2. **Un preprocessing pour les mod√®les de Deep Learning** : les mod√®les de Deep Learning sont inclues dans des  \
    librairies qui contiennent leurs propres fonctions de preprocessing (voici un exemple de dataset image  \
    preprocess√© par keras de Tensorflow: **exemple_preprocess_deeplearning**). ce preprocessing sera adapt√© au cas par cas en fonction  \
    des mod√®les.")
    
    st.write("3. **Un preprocessing pour les mod√®les baseline** : Nous allons entra√Æner par la suite 2 types de mod√®les : des \
    mod√®les deep learning (plus complexes) et des mod√®les baseline (plus simples).  \
    Pour les mod√®les baseline, nous avons r√©duit les images en 64x64 pixels (au lieu de 500x500). \
    Nous les avons pass√©es en niveaux de gris. (voir graphe **exemple_preprocess_baseline**")


