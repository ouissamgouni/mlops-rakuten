import os
import streamlit as st
from PIL import Image
import numpy as np
import pandas as pd
import requests


# This is relative root directory af trai and test images
#IMAGES_ROOT = os.path.join(os.getcwd(), "images")
IMAGES_ROOT = r"https://www.anigraphics.fr/images"


st.title("R√©sultats obtenus")


tabs_title = ["üöÄTexte", "üöÄImage", "üöÄüöÄTexte & image"]
tab1, tab2, tab3 = st.tabs(tabs_title)

# TAB partie texte
with tab1: 
    st.write("### **‚≠êM√©thode d'√©valuation :**")
    st.write("1. Factorisation du pre-proc & vectorisation avec les pipeline")
    st.write("2. Cross-validation avec un StratifiedKFold de 5 splits")
    st.write("3. Choix des m√©triques : balanced accuracy, f1 score, roc-auc et geo (Classes d√©siquilibr√©es)")
    st.divider()
    st.write("#### **‚≠ê6 mod√®les ML, 4 Deep :** Pour chaque mod√®le")
    st.write("- Rapport de classification")
    st.write("- Matrice de confusion")
    st.write("- Graphe roc-au")
    st.write("- Learning curve")
    st.divider()
    st.write("- S√©lection du best mod√®le")
    st.write("- Optimisation du best mod√®le avec un **GridSearchCV**")
    st.divider()
    
    
    st.write("### ‚≠êMod√®les Machine Learning (ML)")
    col1, col2, col3= st.columns(3)
    col1.metric("SVM", "Accuracy", "77%", "off")
    col1.metric("SVM", "f1_score", "77%", "off")
    col1.write("Le **SVM** pr√¥ne l'overfitting et n'a pas √©t√© retenu.")
    col2.metric("Logistic Regression ", "Accuracy", "80%", "normal")
    col2.metric("Logistic Regression ", "f1_score", "79%", "normal")
    col2.write("Le **Logistic Regression** fournit de tr√®s bonnes performances.")
    img_lr = Image.open(os.path.join(os.getcwd(), "images", "log-reg-lear_curve.png"))
    #img_lr = Image.open(requests.get(IMAGES_ROOT +  "/"  + "log-reg-lear_curve.png", stream=True).raw)
    col3.text("üåªLogistic Regression-Courbes des apprentissages")
    col3.image(img_lr)
    img_lr = Image.open(os.path.join(os.getcwd(), "images", "log-reg-cm.png"))
    #img_lr = Image.open(requests.get(IMAGES_ROOT +  "/"  + "log-reg-cm.png", stream=True).raw)
    col3.text("üåªLogistic Regression-Matrice de Confusion")
    col3.image(img_lr)
    
    st.html("<hr>")
    
    col1, col2, col3 = st.columns(3)
    col1.metric("KNN", "Accuracy", "55%", "off")
    col1.metric("KNN", "f1_score", "55%", "off")
    col1.write("Le **KNN** ne fournit pas des r√©sultats satisfaisants.")
    col2.metric("XGBOOST", "Accuracy", "78%", "normal")
    col2.metric("XGBOOST", "f1_score", "78%", "normal")
    col2.write("Le **XGBOOST** fournit des bons r√©sultats presque au m√™me niveau que le Logistic regession.")
    #img_lr = Image.open(requests.get(IMAGES_ROOT +  "/"  + "xgboost-lear_curve.png", stream=True).raw)
    img_lr = Image.open(os.path.join(os.getcwd(), "images", "xgboost-lear_curve.png"))
    col3.text("üåªXGBOOST-Courbes des apprentissages")
    col3.image(img_lr)
    

    st.html("<hr>")
     
    st.write("### ‚≠êMod√®les R√©seaux de Neurones")
    st.html("<h5>üåªBERT (30% data) - Bidirectional Encoder Representations from Transformers - <a href='https://datascientest.com/bert-un-outil-de-traitement-du-langage-innovant' target='_blank'>BERT sur DataScientest</a></h5>")
    col1, col2 = st.columns(2)
    col1.metric("BERT", "Accuracy", "79%", "normal")
    col1.metric("BERT", "f1_score", "78%", "normal")
    
    st.divider()
    
    col1, col2 = st.columns(2)
    col1.html("<h5>üåªLSTM (<a href='https://en.wikipedia.org/wiki/Long_short-term_memory' target='_blank'>Long Short-Term Memory sur wikipedia</a>)</h5>")
    col1.metric("LSTM combin√© avec Conv1D", "Accuracy", "79%", "normal")
    col1.metric("LSTM combin√© avec Conv1D", "f1_score", "79%", "normal")
    #img = Image.open(IMAGES_ROOT + "/lstm-evaluation.png")
    #img = Image.open(requests.get(IMAGES_ROOT +  "/"  + "lstm-evaluation.png", stream=True).raw)
    img = Image.open(os.path.join(os.getcwd(), "images", "lstm-evaluation.png"))
    col1.text("Evaluation du mod√®le sur l'ensemble de test")
    col1.image(img)
    #img = Image.open(IMAGES_ROOT + "/lstm-conv1d-accu_loss.png")
    #img = Image.open(requests.get(IMAGES_ROOT +  "/"  + "lstm-conv1d-accu_loss.png", stream=True).raw)
    img = Image.open(os.path.join(os.getcwd(), "images", "lstm-conv1d-accu_loss.png"))
    col2.text("üåªEvolution de l'accuracy et de la perte")
    col2.image(img)
    #img = Image.open(IMAGES_ROOT + "/lstm-conv1d-cm.png")
    #img = Image.open(requests.get(IMAGES_ROOT +  "/"  + "lstm-conv1d-cm.png", stream=True).raw)
    img = Image.open(os.path.join(os.getcwd(), "images", "lstm-conv1d-cm.png"))
    col2.text("üåªLSTM combin√© avec Conv1D-Matrice de confusion")
    col2.image(img)
    
    st.html("<hr>")
    
    col1, col2 = st.columns(2)
    col1.html("<h5>üåªLSTM renforc√© avec GLOVE (<a href=' https://nlp.stanford.edu/projects/glove/' target='_blank'>Global Vectors for Word Representation</a>)</h5>")
    col1.metric("LSTM renforc√© avec GLOVE", "Accuracy", "80%", "normal")
    col1.metric("LSTM renforc√© avec GLOVE", "f1_score", "80%", "normal")
    col1.write("GLOVE ali√© √† LSTM semble am√©liorer les performances. \
        Le fait qu'il comprend plus de mots en anglais qu'en fran√ßais n'a pa eu l'ffect escompt√©.")
    #img = Image.open(IMAGES_ROOT + "/lstm-glove-accu_loss.png")
    #img = Image.open(requests.get(IMAGES_ROOT +  "/"  + "lstm-glove-accu_loss.png", stream=True).raw)
    img = Image.open(os.path.join(os.getcwd(), "images", "lstm-glove-accu_loss.png"))
    col2.text("üåªEvolution de l'accuracy et de la perte")
    col2.image(img)
    #img = Image.open(IMAGES_ROOT + "/lstm-glove-cm.png")
    #img = Image.open(requests.get(IMAGES_ROOT +  "/"  + "lstm-glove-cm.png", stream=True).raw)
    img = Image.open(os.path.join(os.getcwd(), "images", "lstm-glove-cm.png"))
    col2.text("üåªLSTM combin√© avec Conv1D - Matrice de confusion")
    col2.image(img)
    
    st.html("<hr>")
    
    col1, col2 = st.columns(2)
    col1.write("üåªR√©seaux de Neurones Convolutifs")
    col1.metric("CNN (Conv1D)", "Accuracy", "80%", "normal")  
    col1.metric("CNN (Conv1D)", "f1_score", "80%", "normal")  
    #img = Image.open(IMAGES_ROOT + "/conv1d-accu_loss.png")
    #img = Image.open(requests.get(IMAGES_ROOT +  "/"  + "conv1d-accu_loss", stream=True).raw)
    img = Image.open(os.path.join(os.getcwd(), "images", "conv1d-accu_loss.png"))
    col2.text("üåªEvolution de l'accuracy et de la perte")
    col2.image(img)
    #img = Image.open(IMAGES_ROOT + "/conv1d-mc.png")
    #img = Image.open(requests.get(IMAGES_ROOT +  "/"  + "conv1d-mc.png", stream=True).raw)
    img = Image.open(os.path.join(os.getcwd(), "images", "conv1d-mc.png"))
    col2.text("üåªConv1D - Matrice de confusion")
    col2.image(img)
    
    st.html("<span style='color:green;text-align:center;font-size:24px;height:32px;background-color:#FFFFFF;'>\
        En r√©sum√©, Les deux typologies des mod√®les ML et RNN s√©lectionn√©s fournissent le m√™me niveau de performances.</span>")
    
    
    st.html("<hr>")
    
    
    st.write("### ‚≠êMod√®les ML (approche diff√©rente)")
    st.write("Les mots ne sont pas vectoris√©s, mais transform√©s en variables descriptive avec un nombre limit√© √† 300.\
    Cette approche n'a pas √©t√© retenue pour des questions de performance d'√©valuation des ptr√©dictions.")
    img_approche_ml = Image.open(os.path.join(os.getcwd(), "images", "image-2.png"))
    st.image(img_approche_ml)
    
    st.html("<hr>")
    

    col1, col2, col3, col4, col5 = st.columns(5)
    col1.metric("KNN", "accuracy", "90%", "normal")
    col2.metric("KNN avec une r√©duction PCA de 57% des variables", "accuracy", "87%", "normal")
    col3.metric("Random Forest", "accuracy", "91%", "normal")
    col4.metric("Logistic Regression", "accuracy", "89%", "normal")
    col5.metric("SVC (Support Vector)", "accuracy", "85%", "normal")
    
    
with tab2:
    st.header("R√©sultats obtenus")

     
    st.write("### ‚≠êMod√®les **baseline** images")
    col1, col2 = st.columns(2)
    col1.metric("PCA et Random Forest", "Accuracy", "+49%", delta_color= "inverse")
    col1.metric("PCA et Random Forest", "f1_score (moy)", "+56%", delta_color= "inverse")
    col1.text("üåªRapport de classification")
    #img = Image.open(IMAGES_ROOT + "/pca+RF_classif_report.png")
    img = Image.open(requests.get(IMAGES_ROOT +  "/"  + "pca+RF_classif_report", stream=True).raw)
    col1.image(img)
    #img = Image.open(IMAGES_ROOT + "/PCA+RF_confusion_matrix.png")
    #img = Image.open(requests.get(IMAGES_ROOT +  "/"  + "PCA+RF_confusion_matrix.png", stream=True).raw)
    img = Image.open(os.path.join(os.getcwd(), "images", "PCA+RF_confusion_matrix.png"))
    col2.text("üåªMatrice de confusion")
    col2.image(img)
    st.write(">La r√©duction **PCA** appliqu√©e aux images nous a permis de conserver **90%** de la variance expliqu√©e des images en \
            r√©duisant leur taille de **4096 features (64x64) √† 278**.")
    st.write(">Au-del√† de 200 estimateurs l'accuracy ne progresse plus")
    st.write(">Des √©carts relativement importants en termes d'accuracy des 27 classes, \
        ce qui se r√©percute directement sur la matrice de confusion illustr√©e ci-dessus.")
    st.write("Le **XGBOOST coupl√© avec une PCA** fournit les m√™mes performances que Random Forest avec un temps d'ex√©cution plus long.")
    st.write("En conclusion, la PCA enl√®ve trop d'information des donn√©es image pour obtenir un r√©sultat optimal.")
    
    st.html("<hr>")
    
    st.write("### ‚≠êMod√®les **DEEP-LEARNING** images")
    col1, col2 = st.columns(2)
    col1.metric("RESNET 50", "Accuracy", "+48%", delta_color= "inverse")
    col1.write(">Le **RESTNET 50** s'est arr√™t√© de progresser au bout de 36 EOCHS √† 48% d'accuracy")
    col2.text("üåªRESNET 50 - Tendances de l'accuracy et de la perte")
    #img = Image.open(IMAGES_ROOT + "/acc_loss_resnet.png")
    #img = Image.open(requests.get(IMAGES_ROOT +  "/"  + "acc_loss_resnet", stream=True).raw)
    img = Image.open(os.path.join(os.getcwd(), "images", "acc_loss_resnet.png"))
    col2.image(img)
    
    st.html("<hr>")
    
    
    col1, col2 = st.columns(2)
    col1.metric("EfficentNet B5", "Accuracy", "+46%", delta_color= "inverse")
    col1.write(">Le **EfficentNet B5** s'est arr√™t√© de progresser au bout de 15 EOCHS √† 46% d'accuracy")
    col2.text("üåªEfficentNet B5 - Tendances de l'accuracy et de la perte")
    #img = Image.open(IMAGES_ROOT + "/acc_loss_effnet.png")
    #img = Image.open(requests.get(IMAGES_ROOT +  "/"  + "acc_loss_effnet", stream=True).raw)
    img = Image.open(os.path.join(os.getcwd(), "images", "acc_loss_effnet.png"))
    col2.image(img)
    
    st.html("<hr>")
    
    col1, col2 = st.columns(2)
    col1.metric("ViT (Vision Transformer)", "Accuracy", "+52%", delta_color= "inverse")
    col1.write(">Le **ViT** a bien termin√© ses 10 EPOCHs avec 52% d'accuracy")
    col2.text("üåªViT - Tendances de l'accuracy et de la perte")
    #img = Image.open(IMAGES_ROOT + "/acc_loss_vit.png")
    #img = Image.open(requests.get(IMAGES_ROOT +  "/"  + "acc_loss_vit", stream=True).raw)
    img = Image.open(os.path.join(os.getcwd(), "images", "acc_loss_vit.png"))
    col2.image(img)
    
    st.write(">Les trois mod√®le offrent un niveau de pr√©cision presque √©quivalent √† celui des mod√®les baseline")
    st.write(">les fronti√®res entre certaines cat√©gories est assez mince pour entra√Æner une confusion des mod√®les \
        dans leurs pr√©dictions, comme par exemple 'consoles de jeu', 'consoles, jeux & √©quipement d'occasion'")
    


with tab3:
    st.header("Trois approches diff√©rentes ont √©t√© adopt√©es :")
    
    col1, col2 = st.columns(2)
    col1.write("1. #### ‚≠ê**Entra√Æner un mod√®le multimodal :**")
    col1.write(">Nous avons entra√Æn√© le **CLIP (Contrastive Language-Image pretraining) d'OPEN AI**, qui associe des paires de mots/images dans un espace \
     vectoriel et apprend √† les diff√©rencier en les rapprochant ou en les √©loignant. \
     Malheureusement, la dur√©e d'entra√Ænement √©tant trop longue avec des ressources trop limit√©es, le mod√®le a √©t√© arr√™t√© au bout de 5 √©poques.")
    
    img = Image.open(os.path.join(os.getcwd(), "images", "acc_loss_clip.jpg"))
    col2.image(img)
    
    
    st.divider()
    col1, col2 = st.columns(2)
    col1.write("2. #### ‚≠ê**Entra√Æner un mod√®le de concat√©nation text a images :**")
    col1.write(">**Le principe :** prendre les meilleurs mod√®les texte + meilleur mod√®le image + couche de classification")
    col1.write(">Si on compare les rapports de classification/matrice de confusion des meilleurs mod√®les texte/image, on se rend compte que les mod√®les \
     peuvent se compenser (certaines classes sont bien cat√©goris√©es par le mod√®le image et moins bien par celui du texte, et inversement")
    
    img = Image.open(os.path.join(os.getcwd(), "images", "comp_matrix_txt_img.jpg"))
    col2.image(img)
    
    
    st.divider()
    col1, col2 = st.columns(2)
    col1.write("#### 3. ‚≠ê**Entra√Æner un mod√®le hybride :**")
    col1.write("On entra√Æne donc un mod√®le qui prend en entr√©e texte + image. \
        Le texte est pass√© dans la LR texte gel√©e et produit un vecteur de probas de 27 classes. \
        L'image est pass√©e dans le ViT gel√© et produit un vecteur de probabilit√©s des 27 classes √©galement. \
        On ajoute 3 couches en sortie : 2 classif + 1 dropout pour √©viter l'overfitting. \
        Elles prennent 54 entr√©es (les probabilit√©s des 2 mod√®les) et produisent 27 sorties (les cat√©gories). \
        Les features entra√Ænables sont les probabilit√©s de sortie des 2 mod√®les. \
        Le r√©sultat  : **Accuracy de pr√®s de 95%** sur la validation d√®s la 1√®re EPOCH. \
        On a donc arr√™t√© le mod√®le car l'entra√Ænementest  tr√®s long et performe tr√®s bien.")
   